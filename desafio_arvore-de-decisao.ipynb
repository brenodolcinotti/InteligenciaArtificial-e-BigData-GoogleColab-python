{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOkjLsxQQVc1lMSMn71YIn5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Importando as bibliotecas\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"d0m1MJJHApGw","executionInfo":{"status":"ok","timestamp":1757550507478,"user_tz":180,"elapsed":3,"user":{"displayName":"breno dolcinotti","userId":"15541371352045124988"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Qsj9eXXAO5I","executionInfo":{"status":"ok","timestamp":1757550536564,"user_tz":180,"elapsed":43,"user":{"displayName":"breno dolcinotti","userId":"15541371352045124988"}},"outputId":"d3ecd61c-bd77-4760-8c7c-6c63821ff5a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Acurácia da Decision Tree: 1.00\n","Acurácia do KNN (k=3): 0.50\n","\n","Modelo com melhor desempenho: Decision Tree\n","Motivo: porque obteve uma acurácia maior no conjunto de teste.\n"]}],"source":["# Base de dados\n","dados = {\n","'idade': [22, 25, 28, 35, 40, 45, 50, 55, 60, 65],\n","'renda': [1500, 2000, 2500, 4000, 5000, 6000, 7000, 8000, 10000, 12000],\n","'historico_bom': [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n","'aprovado': [0, 0, 1, 1, 1, 1, 1, 1, 1, 1] # 1 = aprovado, 0 = negado\n","}\n","\n","df = pd.DataFrame(dados)\n","\n","# Separar X e y\n","X = df[['idade', 'renda', 'historico_bom']]\n","y = df['aprovado']\n","\n","# Dividir os dados em treino e teste (80% treino, 20% teste)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Escalonamento dos dados (importante para o KNN)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Treinar o modelo Decision Tree\n","dt_model = DecisionTreeClassifier(random_state=42)\n","dt_model.fit(X_train, y_train)\n","\n","# Treinar o modelo KNN com k=3\n","knn_model = KNeighborsClassifier(n_neighbors=3)\n","knn_model.fit(X_train_scaled, y_train)\n","\n","# Fazer previsões\n","dt_predictions = dt_model.predict(X_test)\n","knn_predictions = knn_model.predict(X_test_scaled)\n","\n","# Calcular a acurácia de cada modelo\n","dt_accuracy = accuracy_score(y_test, dt_predictions)\n","knn_accuracy = accuracy_score(y_test, knn_predictions)\n","\n","# Exibir os resultados\n","print(f\"Acurácia da Decision Tree: {dt_accuracy:.2f}\")\n","print(f\"Acurácia do KNN (k=3): {knn_accuracy:.2f}\")\n","\n","# Comparar e dizer qual foi melhor\n","if dt_accuracy > knn_accuracy:\n","    melhor = \"Decision Tree\"\n","    motivo = \"porque obteve uma acurácia maior no conjunto de teste.\"\n","elif knn_accuracy > dt_accuracy:\n","    melhor = \"KNN (k=3)\"\n","    motivo = \"Porque obteve uma acurácia maior no conjunto de teste.\"\n","else:\n","    melhor = \"Ambos os modelos tiveram o mesmo desempenho\"\n","    motivo = \"Pois suas acurácias foram iguais.\"\n","\n","print(f\"\\nModelo com melhor desempenho: {melhor}\")\n","print(f\"Motivo: {motivo}\")"]}]}